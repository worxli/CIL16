{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"\n",
    "Baseline for CIL project on road segmentation.\n",
    "This simple baseline consits of a CNN with two convolutional+pooling layers with a soft-max loss\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import code\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cil_helper as cil\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.app.flags.DEFINE_string('log_dir', '/tmp/tensorflow_lukas',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "except: \n",
    "    print(tf.app.flags.FLAGS.log_dir)\n",
    "    \n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "TEST_SIZE = 20\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 128 # 64\n",
    "NUM_EPOCHS = 200\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 10\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "\n",
    "PATCH_SIZE = 16\n",
    "EXTRA_CONTEXT = 0\n",
    "CONTEXT_SIZE = EXTRA_CONTEXT + PATCH_SIZE + EXTRA_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "test_dir = \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns all train images in rgb\n",
    "def get_train_imgs():\n",
    "    imgs = []\n",
    "    for i in range(TRAINING_SIZE):\n",
    "        imageid = \"satImage_%.3d\" % (i+1)\n",
    "        image_filename = train_data_filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            raise Exception('File ' + image_filename + ' does not exist')\n",
    "    return np.asarray(imgs)\n",
    "\n",
    "# returns all test images as rgb\n",
    "def get_test_imgs():\n",
    "    imgs = []\n",
    "    for i in range(TEST_SIZE):\n",
    "        imagename = \"test_\" + str(i+1)\n",
    "        image_filename = test_dir + imagename + \"/\" + imagename + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            raise Exception('File ' + image_filename + ' does not exist')\n",
    "    return np.asarray(imgs)\n",
    "\n",
    "# Get prediction overlaid on the original image for given input image\n",
    "def get_prediction_with_overlay(img):\n",
    "    \n",
    "    img_prediction = get_prediction(img)\n",
    "    oimg = cil.make_img_overlay(img[:,:,:3], img_prediction)\n",
    "\n",
    "    return oimg\n",
    "\n",
    "# Get a concatenation of the prediction and groundtruth for given input file\n",
    "def get_prediction_with_groundtruth(img):\n",
    "    \n",
    "    img_prediction = get_prediction(img)\n",
    "    cimg = cil.concatenate_images(img[:,:,:3], img_prediction)\n",
    "\n",
    "    return cimg\n",
    "\n",
    "# Get prediction for given input image \n",
    "def get_prediction(img):\n",
    "    data = np.asarray(cil.img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "    data_node = tf.constant(data)\n",
    "    output = tf.nn.softmax(model(data_node))\n",
    "    output_prediction = s.run(output)\n",
    "    img_prediction = cil.label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "\n",
    "    return img_prediction\n",
    "\n",
    "# returns a numpy array [Saturation, Lightness] of a pixel\n",
    "def sat_light(rgb):\n",
    "    Cmax = rgb.max()\n",
    "    Cmin = rgb.min()\n",
    "    d = Cmax - Cmin\n",
    "    L = (Cmax + Cmin) / 2\n",
    "    S = d / (1 - (abs(2 * L - 1)))\n",
    "    if np.isnan(S):\n",
    "        S = 0\n",
    "    return np.asarray([S, L], dtype=np.float32)\n",
    "\n",
    "#returns edges\n",
    "def texture_features(image):\n",
    "    result = np.empty(list(image.shape) + [2])\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    result[:,:,0] = np.vstack((image[:-1,:] - image[1:,:], np.zeros((1,w))))\n",
    "    result[:,:,1] = np.hstack((image[:,:-1] - image[:,1:], np.zeros((h,1))))\n",
    "    return np.max(np.abs(result),axis=2)\n",
    "\n",
    "NUM_CHANNELS = 6 # RGB, Saturation, Lightness, Edges\n",
    "def preprocess(img):\n",
    "    new_shape = list(img.shape)\n",
    "    new_shape[2] = NUM_CHANNELS\n",
    "    result = np.empty(new_shape, dtype=np.float32)\n",
    "    result[:,:,:3] = img\n",
    "    for y in range(len(img)):\n",
    "        for x in range(len(img[y])):\n",
    "            result[y,x,3:5] = sat_light(result[y,x,:3])\n",
    "    #print('Saturation and lightness computed.')\n",
    "    result[:,:,5] = texture_features(result[:,:,4])\n",
    "    #print('Texture deatures computed.')\n",
    "    return result\n",
    "\n",
    "# takes an array of images, preprocesses them and stores the result\n",
    "# in save_dir/preprocessed.npy\n",
    "def preprocess_imgs(imgs, save_dir):\n",
    "    assert save_dir.endswith('/')\n",
    "    processed = []\n",
    "    for i in range(len(imgs)):\n",
    "        processed.append(preprocess(imgs[i]))\n",
    "        print('Image ' + str(i) + ' preprocessed.')\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    processed_np = np.asarray(processed)\n",
    "    np.save(save_dir + 'preprocessed2.npy', processed_np)\n",
    "    return processed_np\n",
    "\n",
    "def load_preproc(save_dir):\n",
    "    assert save_dir.endswith('/')\n",
    "    return np.load(save_dir + 'preprocessed2.npy')\n",
    "\n",
    "def load_labels():\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, TRAINING_SIZE+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = train_labels_filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    labels = np.asarray(gt_imgs, dtype=np.float32)\n",
    "    return labels\n",
    "\n",
    "def store_channel_to_img(chan):\n",
    "    img = (chan * 255).astype('uint8')\n",
    "    png = Image.fromarray(img)\n",
    "    png.show\n",
    "    return png\n",
    "\n",
    "def show(chan):\n",
    "    chan = chan + chan.min()\n",
    "    chan = chan / chan.max()\n",
    "    img = (chan * 255).astype('uint8')\n",
    "    png = Image.fromarray(img)\n",
    "    png.show\n",
    "    return png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PREPROCESS_TRAIN_DATA = False\n",
    "PREPROCESS_TEST_DATA = False\n",
    "\n",
    "if PREPROCESS_TRAIN_DATA:\n",
    "    preprocess_imgs(get_train_imgs(), train_data_filename)\n",
    "if PREPROCESS_TEST_DATA:\n",
    "    preprocess_imgs(get_test_imgs(), test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 400, 6)\n",
      "(50, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_preproc(train_data_filename)\n",
    "train_labels = load_labels()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# center data\n",
    "train_data = train_data * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step using the {feed_dict} argument to the Run() call below.\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, CONTEXT_SIZE, CONTEXT_SIZE, NUM_CHANNELS),\n",
    "    name='train_data')\n",
    "train_labels_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, cil.NUM_LABELS),\n",
    "    name='train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILTER1_SIZE = 5\n",
    "FILTER1_COUNT = 16\n",
    "FILTER1_STRIDES = [1,1,1,1]\n",
    "\n",
    "POOL1_FACTOR = 3\n",
    "\n",
    "FILTER2_SIZE = 5\n",
    "FILTER2_COUNT = 32\n",
    "FILTER2_STRIDES = [1,1,1,1]\n",
    "\n",
    "POOL2_FACTOR = 5\n",
    "\n",
    "FILTER3_SIZE = 3\n",
    "FILTER3_COUNT = 56\n",
    "FILTER3_STRIDES = [1,1,1,1]\n",
    "\n",
    "POOL3_FACTOR = 9\n",
    "\n",
    "FILTER4_SIZE = 3\n",
    "FILTER4_COUNT = 64\n",
    "FILTER4_STRIDES = [1,1,1,1]\n",
    "\n",
    "POOL4_FACTOR = 1\n",
    "\n",
    "FC1_SIZE = 256\n",
    "FC2_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter1_shape = [FILTER1_SIZE, FILTER1_SIZE, NUM_CHANNELS, FILTER1_COUNT]\n",
    "filter1 = tf.Variable(tf.truncated_normal(filter1_shape, stddev=.1, seed=SEED))\n",
    "conv1_biases = tf.Variable(tf.zeros(shape=[FILTER1_COUNT]))\n",
    "\n",
    "filter2_shape = [FILTER2_SIZE, FILTER2_SIZE, FILTER1_COUNT, FILTER2_COUNT]\n",
    "filter2 = tf.Variable(tf.truncated_normal(filter2_shape, stddev=.1, seed=SEED))\n",
    "conv2_biases = tf.Variable(tf.zeros(shape=[FILTER2_COUNT]))\n",
    "\n",
    "filter3_shape = [FILTER3_SIZE, FILTER3_SIZE, FILTER2_COUNT, FILTER3_COUNT]\n",
    "filter3 = tf.Variable(tf.truncated_normal(filter3_shape, stddev=.1, seed=SEED))\n",
    "conv3_biases = tf.Variable(tf.zeros(shape=[FILTER3_COUNT]))\n",
    "\n",
    "filter4_shape = [FILTER4_SIZE, FILTER4_SIZE, FILTER3_COUNT, FILTER4_COUNT]\n",
    "filter4 = tf.Variable(tf.truncated_normal(filter4_shape, stddev=.1, seed=SEED))\n",
    "conv4_biases = tf.Variable(tf.zeros(shape=[FILTER4_COUNT]))\n",
    "\n",
    "side = CONTEXT_SIZE\n",
    "reshape_depth = side * side * FILTER4_COUNT\n",
    "fc1_weights = tf.Variable(\n",
    "    tf.truncated_normal([reshape_depth, FC1_SIZE], stddev=.1, seed=SEED))\n",
    "fc1_biases = tf.Variable(tf.zeros(shape=[FC1_SIZE]))\n",
    "\n",
    "fc2_weights = tf.Variable(\n",
    "    tf.truncated_normal([FC1_SIZE, FC2_SIZE], stddev=.1, seed=SEED))\n",
    "fc2_biases = tf.Variable(tf.zeros(shape=[FC2_SIZE]))\n",
    "\n",
    "fc_last_weights = tf.Variable(\n",
    "    tf.truncated_normal([FC2_SIZE, cil.NUM_LABELS], stddev=.1, seed=SEED))\n",
    "fc_last_biases = tf.Variable(tf.zeros(shape=[cil.NUM_LABELS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(input_node, dropout=False):\n",
    "    print(input_node.get_shape())\n",
    "\n",
    "    conv1 = tf.nn.conv2d(input_node, filter1, FILTER1_STRIDES, \n",
    "                         padding='SAME', name='conv1')\n",
    "\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "\n",
    "    pool1 = tf.nn.max_pool(relu1, ksize=[1,POOL1_FACTOR,POOL1_FACTOR,1], \n",
    "                           strides=[1,1,1,1], padding='SAME')\n",
    "    print(pool1.get_shape())\n",
    "    ######################\n",
    "    conv2 = tf.nn.conv2d(pool1, filter2, FILTER2_STRIDES, \n",
    "                         padding='SAME', name='conv2')\n",
    "\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "\n",
    "    pool2 = tf.nn.max_pool(relu2, ksize=[1,POOL2_FACTOR,POOL2_FACTOR,1], \n",
    "                           strides=[1,1,1,1], padding='SAME')\n",
    "    print(pool2.get_shape())\n",
    "    ######################\n",
    "    conv3 = tf.nn.conv2d(pool2, filter3, FILTER3_STRIDES, \n",
    "                         padding='SAME', name='conv2')\n",
    "\n",
    "    relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))\n",
    "\n",
    "    pool3 = tf.nn.max_pool(relu3, ksize=[1,POOL3_FACTOR,POOL3_FACTOR,1], \n",
    "                           strides=[1,1,1,1], padding='SAME')\n",
    "    print(pool3.get_shape())\n",
    "    ######################\n",
    "    conv4 = tf.nn.conv2d(pool3, filter4, FILTER4_STRIDES, \n",
    "                         padding='SAME', name='conv2')\n",
    "\n",
    "    relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases))\n",
    "\n",
    "    pool4 = tf.nn.max_pool(relu4, ksize=[1,POOL4_FACTOR,POOL4_FACTOR,1], \n",
    "                           strides=[1,1,1,1], padding='SAME')\n",
    "    print(pool4.get_shape())\n",
    "    ######################\n",
    "    shp = pool4.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool4, [shp[0], shp[1] * shp[2] * shp[3]])\n",
    "    print(reshape.get_shape())\n",
    "\n",
    "    fc1 = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    if (dropout):\n",
    "        fc1 = tf.nn.dropout(fc1, .5, seed=SEED)\n",
    "    print(fc1.get_shape())\n",
    "\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases)\n",
    "    if (dropout):\n",
    "        fc2 = tf.nn.dropout(fc2, .5, seed=SEED)\n",
    "    print(fc2.get_shape())\n",
    "\n",
    "    fc_last = tf.matmul(fc2, fc_last_weights) + fc_last_biases\n",
    "    print(fc_last.get_shape())\n",
    "    return fc_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 16, 16, 6)\n",
      "(128, 16, 16, 16)\n",
      "(128, 16, 16, 32)\n",
      "(128, 16, 16, 56)\n",
      "(128, 16, 16, 64)\n",
      "(128, 16384)\n",
      "(128, 256)\n",
      "(128, 256)\n",
      "(128, 2)\n"
     ]
    }
   ],
   "source": [
    "logits = model(train_data_node, dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, train_labels_node))\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases) +\n",
    "                tf.nn.l2_loss(fc_last_weights) + tf.nn.l2_loss(fc_last_biases))\n",
    "#loss += 5e-4 * regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DECAY_STEP = 100\n",
    "batch_idx = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-6,                # Base learning rate.\n",
    "    batch_idx * BATCH_SIZE,  # Current index into the dataset.\n",
    "    DECAY_STEP,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "#    loss, global_step=batch_idx)\n",
    "opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "optimizer = opt.minimize(loss, global_step=batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_window(image, y, x, truth=None):\n",
    "    #padding the image with wrap-around\n",
    "    window = np.take(np.take(image, \n",
    "                     range(y,y+CONTEXT_SIZE), axis=0,mode='wrap'), \n",
    "                     range(x,x+CONTEXT_SIZE), axis=1,mode='wrap')\n",
    "    if not truth is None:\n",
    "        truth_window = np.take(np.take(truth,\n",
    "     range(y+EXTRA_CONTEXT,y+EXTRA_CONTEXT+PATCH_SIZE), axis=0,mode='wrap'),\n",
    "     range(x+EXTRA_CONTEXT,x+EXTRA_CONTEXT+PATCH_SIZE), axis=1,mode='wrap')\n",
    "        return (window, truth_window)\n",
    "    else:\n",
    "        return window\n",
    "\n",
    "def get_training_samples(batch_size):    \n",
    "    batch = np.empty((batch_size, CONTEXT_SIZE, CONTEXT_SIZE, NUM_CHANNELS))\n",
    "    labels = np.empty((batch_size, cil.NUM_LABELS))\n",
    "    for i in range(batch_size):\n",
    "        pic_idx = random.randrange(0,TRAINING_SIZE)\n",
    "        pic = train_data[pic_idx]\n",
    "        y = random.randrange(0,pic.shape[0])\n",
    "        x = random.randrange(0,pic.shape[1])\n",
    "        \n",
    "        window, truth = get_window(pic, y, x, train_labels[pic_idx])\n",
    "        label = truth.mean()\n",
    "        batch[i] = window\n",
    "        labels[i][0] = label\n",
    "        labels[i][1] = 1 - label\n",
    "    return (batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(img,lbl) = get_training_samples(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAACfUlEQVR4nAXBy04TUQAA0Puce2fu\nPDotpYUWEyKoidG1WxMXbP0LP8F/MX6NunJJCCEiUSwUSjt9zOPO3KfnwM+f+tN1aRGrBb3P8Dpy\nQo7fXS7TnbpLhxcnVST9i0f4c1wH6u3HH98Q7mpFEPMeu/Z5oaONPSjQ8VI3EVhHYf64RVt5uS9V\nLIBu57hEscarwM4j1/AM7Gi6q61arjLaq0Zn5/F9OCiCxKi8EuXTiN/1vpMuBNJ7h2wIt38HRhtC\njT7f27uZYLrZXU+qQOPDAiksVUwVuyOYe9dhSVnYQuqtdcGvPioHsyrioFDNtqeZf5w+YTjpzdGH\n2TPyj1GvmRSWk4AVThEPADQQBohBHaqJggyQRWK4iigFICaVUp77tEbWN63ATpPU+43r6WQrEPeZ\nciQofRW1Q0PLq8EWCYUx9B3DyCGHKLcm7riArvH5cgCblFqPuZmMZsugw5Naktw6YISDpSEBlUD5\nKO920yVVBle59SLfr5I3vx+YGl4fZS5Yk8T1bzNGasBQ1UReATyt3GilbM3vvR0+yNfzxcsyvjio\nRoubIu4IKdhht+4CWPeywJcQq0IEnfMp3LidyDdWE3pz0BU5iZ90DR3p/9H1xNDYtQ7aCHBHjMSL\nqOFoKIfSBSVyZO0Ma5mKTqYNR5zYFuaL6LBf93Y0lEBtM9thJoH2WmHIqAYeMdqGRSxu4QNapeB0\nVr2/FvOxVhmSIFGJBSFRdIslqEOsqVDGN6RmjX8lATmbx1QmX/dvxSKSpO1yAz1oUhRviGHIhe2a\nQlsytNPc3t8kmnw5heMHfxUymOdd2iZhB0BAS4qccQhCl3AAQtPQEBTs6Lhh/wGkGnVqPo/YXQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=16x16 at 0x7F835040D630>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(img[0,:,:,3:]/2+.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n"
     ]
    }
   ],
   "source": [
    "s.run(tf.initialize_all_variables())\n",
    "print ('Initialized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch, labels = get_training_samples(BATCH_SIZE)\n",
    "\n",
    "feed_dict = { train_data_node: batch\n",
    "                    , train_labels_node: labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.run(optimizer, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: 1.29971\n",
      "Var: 0.168956\n",
      "Ratio: 7.69259\n",
      "\n",
      "\n",
      "Grad: 14.1659\n",
      "Var: -1.53676e-05\n",
      "Ratio: -921808.0\n",
      "\n",
      "\n",
      "Grad: 9.24941\n",
      "Var: 0.019656\n",
      "Ratio: 470.565\n",
      "\n",
      "\n",
      "Grad: 6.91624\n",
      "Var: -7.00364e-06\n",
      "Ratio: -987521.0\n",
      "\n",
      "\n",
      "Grad: 6.5277\n",
      "Var: 0.0953063\n",
      "Ratio: 68.4918\n",
      "\n",
      "\n",
      "Grad: 3.45631\n",
      "Var: -3.28297e-06\n",
      "Ratio: -1.0528e+06\n",
      "\n",
      "\n",
      "Grad: 9.96509\n",
      "Var: 0.0542281\n",
      "Ratio: 183.762\n",
      "\n",
      "\n",
      "Grad: 2.78218\n",
      "Var: -2.44939e-06\n",
      "Ratio: -1.13586e+06\n",
      "\n",
      "\n",
      "Grad: 2.20407\n",
      "Var: -0.0577689\n",
      "Ratio: -38.1532\n",
      "\n",
      "\n",
      "Grad: 0.211232\n",
      "Var: -1.78738e-07\n",
      "Ratio: -1.1818e+06\n",
      "\n",
      "\n",
      "Grad: 17.675\n",
      "Var: 0.151721\n",
      "Ratio: 116.496\n",
      "\n",
      "\n",
      "Grad: 0.165171\n",
      "Var: -1.19327e-07\n",
      "Ratio: -1.38418e+06\n",
      "\n",
      "\n",
      "Grad: 52.4268\n",
      "Var: 0.183034\n",
      "Ratio: 286.432\n",
      "\n",
      "\n",
      "Grad: 0.490957\n",
      "Var: -5.33685e-07\n",
      "Ratio: -919937.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (grad,var) in opt.compute_gradients(loss):\n",
    "    if grad is not None:\n",
    "        grads = grad.eval(session=s, feed_dict=feed_dict)\n",
    "        i = grads.argmax()\n",
    "        print('Grad: ' + str(grads.flat[i]))\n",
    "        val = var.eval(session=s).flat[i]\n",
    "        print('Var: ' + str(val))\n",
    "        print('Ratio: ' + str(grads.flat[i]/val))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i in range(RECORDING_STEP):\n",
    "        batch, labels = get_training_samples(BATCH_SIZE)\n",
    "\n",
    "        feed_dict = { train_data_node: batch\n",
    "                    , train_labels_node: labels}\n",
    "        \n",
    "        s.run(optimizer, feed_dict=feed_dict)\n",
    "\n",
    "    batch, labels = get_training_samples(BATCH_SIZE)\n",
    "    feed_dict = { train_data_node: batch\n",
    "                , train_labels_node: labels}\n",
    "    l, pred = s.run([loss, output], feed_dict=feed_dict)\n",
    "    error_rate = cil.error_rate(pred,labels)\n",
    "    print('Epoch ' + str(epoch) + ':')\n",
    "    print('Loss: ' + str(l))\n",
    "    print('Error: ' + str(error_rate))\n",
    "    losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(1, CONTEXT_SIZE, CONTEXT_SIZE, NUM_CHANNELS),\n",
    "    name='pred_input')\n",
    "pred_output = tf.nn.softmax(model(pred_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = train_data[:1]\n",
    "# assuming images are quadratic\n",
    "num_patches = imgs[0].shape[0] // PATCH_SIZE\n",
    "truth = np.empty((len(imgs), num_patches, num_patches, cil.NUM_LABELS))\n",
    "preds = np.empty((len(imgs), num_patches, num_patches, cil.NUM_LABELS))\n",
    "for img_idx in range(len(imgs)):\n",
    "    img = imgs[img_idx]\n",
    "    for patch_y in range(num_patches):\n",
    "        y = patch_y * PATCH_SIZE - EXTRA_CONTEXT\n",
    "        for patch_x in range(num_patches):\n",
    "            x = patch_x * PATCH_SIZE - EXTRA_CONTEXT\n",
    "            window, window_truth = get_window(img, y, x, train_labels[img_idx])\n",
    "            pred = s.run(pred_output, {pred_input: [window]})\n",
    "            preds[img_idx, patch_y, patch_x] = pred\n",
    "            label = window_truth.mean()\n",
    "            truth[img_idx, patch_y, patch_x, 0] = label\n",
    "            truth[img_idx, patch_y, patch_x, 1] = 1 - label\n",
    "    print('Done with image ' + str(img_idx))\n",
    "truth = truth.reshape((len(imgs) * num_patches * num_patches, cil.NUM_LABELS))\n",
    "preds = preds.reshape((len(imgs) * num_patches * num_patches, cil.NUM_LABELS))\n",
    "error_rate = cil.error_rate(preds, truth)\n",
    "print(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_m = np.empty(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_m[:,0] = preds[:,0]\n",
    "preds_m[:,1] = 1 - preds_m[:,0]\n",
    "cil.error_rate(preds_m, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_img = cil.label_to_img(imgs[0].shape[0],imgs[0].shape[1],\n",
    "                             PATCH_SIZE,PATCH_SIZE,preds_m)\n",
    "show(label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Running prediction on training set\")\n",
    "prediction_training_dir = \"predictions_training/\"\n",
    "if not os.path.isdir(prediction_training_dir):\n",
    "    os.mkdir(prediction_training_dir)\n",
    "    \n",
    "for i in range(TRAINING_SIZE):\n",
    "    pimg = get_prediction_with_groundtruth(train_preproc[i])\n",
    "    Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i+1) + \".png\")\n",
    "    oimg = get_prediction_with_overlay(train_preproc[i])\n",
    "    oimg.save(prediction_training_dir + \"overlay-8x8_\" + str(i+1) + \".png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Running prediction on test set\")\n",
    "prediction_test_dir = \"predictions_test/\"\n",
    "if not os.path.isdir(prediction_test_dir):\n",
    "    os.mkdir(prediction_test_dir)\n",
    "\n",
    "test_preproc = load_preproc(test_dir)\n",
    "for i in range(TEST_SIZE):\n",
    "    pred = get_prediction(test_preproc[i])\n",
    "    pimg = cil.img_float_to_uint8(pred)\n",
    "    Image.fromarray(pimg).save(prediction_test_dir + \"prediction_\" + str(i+1) + \".png\")\n",
    "    oimg = cil.make_img_overlay(test_preproc[i], pred)\n",
    "    oimg.save(prediction_test_dir + \"overlay-8x8_\" + str(i+1) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "th = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "def save(submission_filename):\n",
    "    #subm#ission_filename = 'submission_07.csv'\n",
    "    image_filenames = []\n",
    "    for i in range(1, 51):\n",
    "        imagename = 'prediction_' + str(i)\n",
    "        image_filename = 'predictions_test/' + imagename + '.png'\n",
    "        print(image_filename)\n",
    "        image_filenames.append(image_filename)\n",
    "    masks_to_submission(submission_filename, *image_filenames)\n",
    "    \n",
    "save('submission_lukas_11_2.5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvlis",
   "language": "python",
   "name": "venvlis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
