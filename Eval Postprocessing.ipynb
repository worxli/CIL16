{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cil_helper as cil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign a label to a patch v\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.75 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = np.sum(v)\n",
    "    if df < foreground_threshold:\n",
    "       return [0, 1]\n",
    "    else:\n",
    "       return [1, 0]\n",
    "\n",
    "# Extract label images\n",
    "def extract_labels(filename, num_images, IMG_PATCH_SIZE):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [cil.img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(np.float32)\n",
    "\n",
    "data_dir = 'training/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIXEL_DEPTH = 255\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * PIXEL_DEPTH).round().astype(np.uint8)\n",
    "    return rimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "    color_mask[:,:,0] = predicted_img*PIXEL_DEPTH\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    th = 0.25\n",
    "    df = np.mean(patch)\n",
    "    if df > th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_to_label(patch, th):\n",
    "    df = np.mean(patch)\n",
    "    if df >= th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mask_to_submission_strings(im, img_number):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number+1, j, i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def masks_to_submission(submission_filename, *image_files):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')         \n",
    "        for ind, fn in enumerate(image_files[0:]):\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn, ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
    "def collect_masks(name, ending, patches, id, th):\n",
    "    train_labels = extract_labels(train_labels_filename, TRAINING_SIZE+VALIDATION_SIZE, 16)\n",
    "    TEST_IMG_SIZE = 400\n",
    "    img = np.zeros((TEST_IMG_SIZE,TEST_IMG_SIZE))\n",
    "    for p in patches:\n",
    "        imagename = name + str(p) + '_' + str(id) + ending\n",
    "        #print(imagename)\n",
    "        image = mpimg.imread(imagename)\n",
    "        image = image[:,TEST_IMG_SIZE:,:]\n",
    "        image = rgb2gray(image) \n",
    "        for j in range(0, image.shape[1], p):\n",
    "            for i in range(0, image.shape[0], p):\n",
    "                label = np.mean(image[i:i + p, j:j + p])\n",
    "                #pred_label = np.mean(img[i:i + p, j:j + p])\n",
    "                # set new label\n",
    "                img[i:i + p, j:j + p] = img[i:i + p, j:j + p]+label\n",
    "    \n",
    "    p = 16\n",
    "    labels = []\n",
    "    for j in range(0, img.shape[1], p):\n",
    "            for i in range(0, img.shape[0], p):\n",
    "                patch = img[i:i + p, j:j + p]\n",
    "                label = summary_to_label(patch,th)\n",
    "                img[i:i + p, j:j + p] = label\n",
    "                labels.append([label, 1-label])\n",
    "                \n",
    "    # error calc \n",
    "    labels = np.asarray(labels)\n",
    "    err = cil.error_rate(labels, train_labels[labels.shape[0]*id:labels.shape[0]*(id+1)])\n",
    "    print(err)   \n",
    "    error.append(err)\n",
    "            \n",
    "    # make overlay\n",
    "    testname = 'training/images/satImage_0' + str(id) + '.png'\n",
    "    testimg = mpimg.imread(testname)        \n",
    "    oimg = make_img_overlay(testimg, img)\n",
    "    oimg.save('predictions_training/' + \"overlay-post-comb_\" + str(id) + \".png\")\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 40\n",
    "VALIDATION_SIZE = 10  # Size of the validation set.\n",
    "def save(submission_filename, th):\n",
    "    #subm#ission_filename = 'submission_07.csv'\n",
    "    patches = [2,8,16]\n",
    "    images = []\n",
    "    for i in range(TRAINING_SIZE, TRAINING_SIZE+VALIDATION_SIZE):\n",
    "    #for i in range(40, 41):\n",
    "        images.append(collect_masks('predictions_training/prediction__eval_postproc', '.png', patches, i, th))\n",
    "    masks_to_submission(submission_filename, *images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.32\n",
      "50.88\n",
      "44.0\n",
      "42.88\n",
      "40.96\n",
      "37.28\n",
      "40.48\n",
      "46.4\n",
      "42.88\n",
      "43.04\n",
      "Mean: 43.312\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 1)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.16\n",
      "34.88\n",
      "40.8\n",
      "31.84\n",
      "30.24\n",
      "24.48\n",
      "27.84\n",
      "36.96\n",
      "32.96\n",
      "30.56\n",
      "Mean: 32.272\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 1.5)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.68\n",
      "29.76\n",
      "34.72\n",
      "26.88\n",
      "20.8\n",
      "16.64\n",
      "22.4\n",
      "31.2\n",
      "28.0\n",
      "25.76\n",
      "Mean: 25.984\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 2)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.28\n",
      "24.8\n",
      "27.84\n",
      "20.8\n",
      "13.92\n",
      "12.32\n",
      "18.88\n",
      "25.92\n",
      "23.2\n",
      "19.84\n",
      "Mean: 20.48\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 2.5)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.64\n",
      "23.36\n",
      "23.84\n",
      "16.96\n",
      "9.76\n",
      "11.52\n",
      "18.24\n",
      "22.56\n",
      "20.32\n",
      "16.32\n",
      "Mean: 17.552\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 2.75)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.6\n",
      "21.44\n",
      "21.76\n",
      "14.24\n",
      "7.2\n",
      "10.24\n",
      "16.96\n",
      "20.48\n",
      "16.8\n",
      "11.84\n",
      "Mean: 15.056\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 2.95)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.28\n",
      "23.68\n",
      "24.64\n",
      "18.08\n",
      "10.24\n",
      "12.0\n",
      "17.92\n",
      "23.84\n",
      "20.48\n",
      "17.44\n",
      "Mean: 18.16\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "save('submission_eval_lukas.csv', 2.7)\n",
    "print(\"Mean: \" + str(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
